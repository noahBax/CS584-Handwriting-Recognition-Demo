{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the model\n",
    "model = tf.keras.models.load_model('nocra.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH  = 28\n",
    "IMG_HEIGHT = 28\n",
    "IMG_CHANNELS = 1\n",
    "\n",
    "IMG_DIR = \"./demoSet\"\n",
    "IMG_LABELS = ['lower_0', 'lower_1', 'lower_2', 'lower_3', 'lower_4',\n",
    "\t\t\t  'lower_5', 'lower_6', 'lower_7', 'lower_8', 'lower_9',\n",
    "\t\t\t  'lower_a', 'lower_b', 'lower_d', 'lower_e', 'lower_f',\n",
    "\t\t\t  'lower_g', 'lower_h', 'lower_n', 'lower_q', 'lower_r',\n",
    "\t\t\t  'lower_t', 'upper_A', 'upper_B', 'upper_C', 'upper_D',\n",
    "\t\t\t  'upper_E', 'upper_F', 'upper_G', 'upper_H', 'upper_I',\n",
    "\t\t\t  'upper_J', 'upper_K', 'upper_L', 'upper_M', 'upper_N',\n",
    "\t\t\t  'upper_O', 'upper_P', 'upper_Q', 'upper_R', 'upper_S',\n",
    "\t\t\t  'upper_T', 'upper_U', 'upper_V', 'upper_W', 'upper_X',\n",
    "\t\t\t  'upper_Y', 'upper_Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2350 files belonging to 47 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load in the demo dataset\n",
    "\n",
    "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "\tIMG_DIR,\n",
    "\tlabels=\"inferred\",\n",
    "\tlabel_mode=\"categorical\",           \n",
    "\timage_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    color_mode=\"grayscale\",\n",
    "\tclass_names=IMG_LABELS,\n",
    "\tbatch_size=9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the dataset prior to the model\n",
    "\n",
    "def normalize_image(image, label):\n",
    "\timage = tf.cast(image, tf.float32) / 255.0\n",
    "\treturn image, label\n",
    "\n",
    "smooth_images = dataset.map(normalize_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8924 - loss: 0.2733\n"
     ]
    }
   ],
   "source": [
    "# Make predictions and show results\n",
    "results = model.evaluate(smooth_images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
