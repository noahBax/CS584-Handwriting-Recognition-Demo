{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH  = 28\n",
    "IMG_HEIGHT = 28\n",
    "IMG_CHANNELS = 1\n",
    "\n",
    "IMG_DIR = \"./EMNIST\"\n",
    "IMG_LABELS = ['lower_0', 'lower_1', 'lower_2', 'lower_3', 'lower_4',\n",
    "\t\t\t  'lower_5', 'lower_6', 'lower_7', 'lower_8', 'lower_9',\n",
    "\t\t\t  'lower_a', 'lower_b', 'lower_d', 'lower_e', 'lower_f',\n",
    "\t\t\t  'lower_g', 'lower_h', 'lower_n', 'lower_q', 'lower_r',\n",
    "\t\t\t  'lower_t', 'upper_A', 'upper_B', 'upper_C', 'upper_D',\n",
    "\t\t\t  'upper_E', 'upper_F', 'upper_G', 'upper_H', 'upper_I',\n",
    "\t\t\t  'upper_J', 'upper_K', 'upper_L', 'upper_M', 'upper_N',\n",
    "\t\t\t  'upper_O', 'upper_P', 'upper_Q', 'upper_R', 'upper_S',\n",
    "\t\t\t  'upper_T', 'upper_U', 'upper_V', 'upper_W', 'upper_X',\n",
    "\t\t\t  'upper_Y', 'upper_Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in datasets using tensorflow\n",
    "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "\tIMG_DIR,\n",
    "\tlabels=\"inferred\",\n",
    "\tlabel_mode=\"categorical\",           \n",
    "\timage_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    color_mode=\"grayscale\",\n",
    "\tclass_names=IMG_LABELS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw images are in the range 0..255 and we want to normalize the dataset\n",
    "def normalize_image(image, label):\n",
    "\timage = tf.cast(image, tf.float32) / 255.0\n",
    "\treturn image, label\n",
    "\n",
    "smooth_images = dataset.map(normalize_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make the training move a little faster, there are a few options we tried\n",
    "\n",
    "# smooth_images = smooth_images.cache()  # This can take up a LOT of memory, so uncomment if you have some available\n",
    "smooth_images = smooth_images.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into test and train sets 80/20\n",
    "train_size = int(0.8 * len(smooth_images))\n",
    "\n",
    "train_set = smooth_images.take(train_size)\n",
    "val_set   = smooth_images.skip(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPool2D, Flatten, Dropout, Dense\n",
    "# Create the model\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(Conv2D(\n",
    "\tinput_shape=(IMG_WIDTH, IMG_HEIGHT, IMG_CHANNELS),\n",
    "\tkernel_size=5,\n",
    "\tfilters=8,\n",
    "\tstrides=1,\n",
    "\tactivation=tf.keras.activations.relu\n",
    "))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPool2D(\n",
    "\tpool_size=(2, 2),\n",
    "\tstrides=(2, 2)\n",
    "))\n",
    "\n",
    "model.add(Conv2D(\n",
    "\tkernel_size=5,\n",
    "\tfilters=16,\n",
    "\tstrides=1,\n",
    "\tactivation=tf.keras.activations.relu\n",
    "))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPool2D(\n",
    "\tpool_size=(2, 2),\n",
    "\tstrides=(2, 2)\n",
    "))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(\n",
    "\tunits=200,\n",
    "\tactivation=tf.keras.activations.relu\n",
    "))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(\n",
    "\tunits=len(IMG_LABELS),\n",
    "\tactivation=tf.keras.activations.softmax,\n",
    "\tkernel_initializer=tf.keras.initializers.VarianceScaling()\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a quick summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "\n",
    "sgd_optimizer = tf.keras.optimizers.SGD()\n",
    "model.compile(\n",
    "\toptimizer=sgd_optimizer,\n",
    "\tloss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "\tmetrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "\n",
    "training_history = model.fit(\n",
    "\ttrain_set,\n",
    "\tepochs=25,\n",
    "\tvalidation_data=val_set\n",
    ")\n",
    "\n",
    "print(\"Model is done training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loss and accuracy\n",
    "train_loss = training_history.history['loss']\n",
    "train_accuracy = training_history.history['accuracy']\n",
    "\n",
    "# Testing loss and accuracy\n",
    "val_loss = training_history.history.get('val_loss')\n",
    "val_accuracy = training_history.history.get('val_accuracy')\n",
    "\n",
    "# Print statistics for each epoch\n",
    "for epoch in range(len(train_loss)):\n",
    "    print(f\"Epoch {epoch+1}:\")\n",
    "    print(f\"  Training Loss: {train_loss[epoch]:.4f}, Training Accuracy: {train_accuracy[epoch]:.4f}\")\n",
    "    if val_loss and val_accuracy:\n",
    "        print(f\"  Validation Loss: {val_loss[epoch]:.4f}, Validation Accuracy: {val_accuracy[epoch]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results of training\n",
    "model.save(\"nocra_demo_train.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
